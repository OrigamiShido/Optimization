{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738cbc3a9cbce68e",
   "metadata": {},
   "source": [
    "# 使用多种方法求解最优化问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T13:20:49.685759Z",
     "start_time": "2024-05-06T13:20:44.997690Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梯度下降法:\n",
      "最优解：[[0.19385489]\n",
      " [0.16561179]\n",
      " [0.11663432]\n",
      " [0.12450401]],使用时间：1.9877238273620605,迭代次数：820\n",
      "牛顿法:\n",
      "最优解：[[-1.05047168e+00]\n",
      " [-6.12759067e+02]\n",
      " [ 6.14638827e+02]\n",
      " [ 6.84509712e+03]],使用时间：0.10029959678649902,迭代次数：53\n",
      "阻尼牛顿法:\n",
      "最优解：[[0.19270801]\n",
      " [0.19128813]\n",
      " [0.12201901]\n",
      " [0.13616184]],使用时间：0.06918692588806152,迭代次数：15\n",
      "拟牛顿法:\n",
      "最优解：[[0.19275377]\n",
      " [0.19217157]\n",
      " [0.12292782]\n",
      " [0.13653408]],使用时间：0.0486905574798584,迭代次数：31\n",
      "共轭梯度法:\n",
      "最优解：[[0.19378626]\n",
      " [0.16705643]\n",
      " [0.11695686]\n",
      " [0.12515235]],使用时间：1.8550806045532227,迭代次数：572\n",
      "LMF法:\n",
      "最优解：[[0.19385556]\n",
      " [0.16570258]\n",
      " [0.11668666]\n",
      " [0.12454144]],使用时间：0.5791974067687988,迭代次数：444\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "y = np.mat([0.1957,0.1947,0.1735,0.1600,0.0844,0.0627,0.0456,0.0342,0.0323,0.0235,0.0246]).T\n",
    "t = np.mat([4.0000,2.0000,1.0000,0.5000,0.2500,0.1670,0.1250,0.1000,0.0833,0.0714,0.0625]).T\n",
    "\n",
    "def targetfunction(x):\n",
    "    result=0.0\n",
    "    for i in range(11):\n",
    "        result+=(y[i,0]-fsub(x,t[i,0]))**2\n",
    "    return result\n",
    "\n",
    "def fsub(x,t):\n",
    "    return x[0,0]*(t**2+x[1,0]*t)/(t**2+x[2,0]*t+x[3,0])\n",
    "\n",
    "def grad(f, x):\n",
    "    '''\n",
    "    求梯度\n",
    "    :param f: 函数\n",
    "    :param x: 向量\n",
    "    :return: 梯度向量\n",
    "    '''\n",
    "    delta=0.0000001\n",
    "    gradmatrix=np.zeros(x.shape)\n",
    "    fx=f(x)\n",
    "    it=np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix=it.multi_index\n",
    "        old_value=(np.float64)(x[ix])\n",
    "        x[ix]=(np.float64)(old_value+delta)\n",
    "        fxd=f(x)\n",
    "        gradmatrix[ix]=(fxd-fx)/delta\n",
    "        x[ix]=old_value\n",
    "        it.iternext()\n",
    "    return np.mat(gradmatrix)\n",
    "\n",
    "def Hessian(f,x):\n",
    "    '''\n",
    "    求Hessian矩阵\n",
    "    :param f: 函数\n",
    "    :param x: 初始点\n",
    "    :param epsilon: epsilon\n",
    "    :return: f在x处的Hessian矩阵\n",
    "    '''\n",
    "    delta=0.001\n",
    "    n=np.size(x)\n",
    "    HessianMatrix=np.zeros((n,n))\n",
    "    gx0=grad(f,x)\n",
    "    for i in range(0,n):\n",
    "        old_value = (np.float64)(x[i,0])\n",
    "        x[i,0] = (np.float64)(old_value + delta)\n",
    "        gxk=grad(f,x)\n",
    "        for j in range(0,n):\n",
    "            HessianMatrix[i,j]=(np.float64)((gxk[j,0]-gx0[j,0])/delta)\n",
    "        x[i,0]=old_value\n",
    "    return np.mat(HessianMatrix)\n",
    "\n",
    "def armijo(f,xk,dk,rho):\n",
    "    cnt=0\n",
    "    alpha=1\n",
    "    vtr=xk\n",
    "    vtr_after=xk+alpha*dk\n",
    "    while f(vtr_after)>f(vtr)+rho*grad(f,xk).T*dk*alpha:\n",
    "        alpha=rho*alpha\n",
    "        vtr_after=xk+alpha*dk\n",
    "    return alpha\n",
    "\n",
    "def Graddecent(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "    gk=grad(function,xk)\n",
    "    while(np.linalg.norm(gk)>epsilon):\n",
    "        dk=-grad(function,xk)\n",
    "        alpha=armijo(function,xk,dk,0.5)\n",
    "        xk=xk+alpha*dk\n",
    "        gk=grad(function,xk)\n",
    "        cnt=cnt+1\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "\n",
    "def Newton(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "    gk=grad(function,xk)\n",
    "    while(np.linalg.norm(gk)>epsilon):\n",
    "        if (np.linalg.det(Hessian(function,xk))<epsilon):\n",
    "            dk=-gk\n",
    "        else:\n",
    "            dk=-np.linalg.inv(Hessian(function,xk))*gk\n",
    "        xk=xk+dk\n",
    "        gk=grad(function,xk)\n",
    "        cnt=cnt+1\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "        \n",
    "def dampnewton(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "    gk=grad(function,xk)\n",
    "    while(np.linalg.norm(gk)>epsilon):\n",
    "        if (np.linalg.det(Hessian(function,xk))<epsilon):\n",
    "            dk=-gk\n",
    "        else:\n",
    "            dk=-np.linalg.inv(Hessian(function,xk))*gk\n",
    "        alpha=armijo(function,xk,dk,0.5)\n",
    "        xk=xk+alpha*dk\n",
    "        gk=grad(function,xk)\n",
    "        cnt=cnt+1\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "\n",
    "def asNewton(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "\n",
    "    gk=grad(function,xk)\n",
    "    n=np.size(xk)\n",
    "    H=np.mat(np.eye(n))\n",
    "    while(np.linalg.norm(grad(function,xk))>epsilon):\n",
    "        cnt=cnt+1\n",
    "        dk=-H*gk\n",
    "        alpha=armijo(function,xk,dk,0.5)\n",
    "        sk=alpha*dk\n",
    "        xr=xk+alpha*dk\n",
    "        yk=grad(function,xr)-gk\n",
    "        H = H + np.linalg.det((1+(yk.T*H*yk)/(yk.T*sk)))*((sk*sk.T)/(yk.T*sk))-((sk*yk.T*H+H*yk*sk.T)/(yk.T*sk))# BFGS\n",
    "        xk=xr\n",
    "        gk=grad(function,xk)\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "\n",
    "def Conjugategrad(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "    gk=grad(function,xk)\n",
    "    dk=-gk\n",
    "    while(np.linalg.norm(grad(function,xk))>epsilon):\n",
    "        alpha=armijo(function,xk,dk,0.5)\n",
    "        xk=xk+alpha*dk\n",
    "        gknew=grad(function,xk)\n",
    "        betak=(gknew.T*(gknew-gk))/(gk.T*gk)\n",
    "        if(betak<0):\n",
    "            betak=0# PRP+\n",
    "        dk=-gk+dk*betak\n",
    "        gk=gknew\n",
    "        cnt=cnt+1\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "\n",
    "def LMF(function,x,epsilon):\n",
    "    start=time.time()\n",
    "    cnt=0\n",
    "    xk=x\n",
    "    vk=1\n",
    "    gk=grad(function,xk)\n",
    "    while(np.linalg.norm(grad(function,xk))>epsilon):\n",
    "        cnt=cnt+1\n",
    "        J = (np.mat)(np.zeros([11, 4]))\n",
    "        rk= (np.mat)(np.zeros([11,1]))\n",
    "        for i in range(0,11):                   #计算Jaccobi行列式\n",
    "            r=lambda x:y[i,0]-fsub(x,t[i,0])       #定义ri(x)\n",
    "            gr=grad(r,xk)\n",
    "            for j in range(0,4):\n",
    "                J[i,j]=gr[j,0]\n",
    "            rk[i,0]=r(xk)\n",
    "        I=(np.mat)(np.eye(4))\n",
    "        J = (np.float64)(J)\n",
    "        I = (np.float64)(I)\n",
    "        rk= (np.float64)(rk)\n",
    "        if(abs(np.linalg.det(J.T.dot(J)+vk*I))<0.1):\n",
    "            dk=-gk\n",
    "        else:\n",
    "            dk=np.linalg.inv(J.T*J+vk*I)*(-J.T*rk)\n",
    "        f_delta=function(xk)-function(xk+dk)\n",
    "        q_delta=0.5*(dk.T.dot(vk*dk-gk))[0,0]\n",
    "        gama=f_delta/q_delta\n",
    "        if(gama<0.25):\n",
    "            vk=4*vk\n",
    "        elif (gama>0.75):\n",
    "            vk=0.5*vk\n",
    "        if(gama>0):\n",
    "            xk=xk+dk\n",
    "            gk=grad(function,xk)\n",
    "    end=time.time()-start\n",
    "    return xk,end,cnt\n",
    "\n",
    "X=np.mat([0.0,0.0,0.0,0.0]).T  \n",
    "x1,t1,k1=Graddecent(targetfunction,X,1e-4)\n",
    "print(\"梯度下降法:\")\n",
    "print(f\"最优解：{x1},使用时间：{t1},迭代次数：{k1}\")\n",
    "x2,t2,k2=Newton(targetfunction,X,1e-4)\n",
    "print(\"牛顿法:\")\n",
    "print(f\"最优解：{x2},使用时间：{t2},迭代次数：{k2}\")\n",
    "x3,t3,k3=dampnewton(targetfunction,X,1e-4)\n",
    "print(\"阻尼牛顿法:\")\n",
    "print(f\"最优解：{x3},使用时间：{t3},迭代次数：{k3}\")\n",
    "x4,t4,k4=asNewton(targetfunction,X,1e-4)\n",
    "print(\"拟牛顿法:\")\n",
    "print(f\"最优解：{x4},使用时间：{t4},迭代次数：{k4}\")\n",
    "x5,t5,k5=Conjugategrad(targetfunction,X,1e-4)\n",
    "print(\"共轭梯度法:\")\n",
    "print(f\"最优解：{x5},使用时间：{t5},迭代次数：{k5}\")\n",
    "x6,t6,k6=LMF(targetfunction,X,1e-4)\n",
    "print(\"LMF法:\")\n",
    "print(f\"最优解：{x6},使用时间：{t6},迭代次数：{k6}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
